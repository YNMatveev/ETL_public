# ETL-процесс для переноса данных из PostgreSQL в Elasticsearch

Это учебный проект, цель которого - реализация отказоустойчивого ETL-процесса для переноса данных из PostgreSQL в Elasticsearch.

В PostgreSQL загружены данные по фильмам, актерам и жанрам (структура находится в файле src/db/movies_db_schema.ddl).

При первом запуске ETL будет создан индекс Elasticsearch (мэппинг и настройки индкекса находятся в файле postgres_to_es/index_config.json) и в будут перенесены исходные данные из PostgreSQL. В случае появления новых или обновления записей в PostgreSQL, они будут перенесены в Elasticsearch. Поиск новых данных будет производится по полю "updated_at". PostgreSQL будет проверяться на наличие новых данных через интервал, установленный в настройке - "fetch_delay".

Так же время последнего обновления индекса Elasticsearch будет сохраняться в файл state.yaml (имя файла можно изменить в настройках - "state_file_name"), чтобы процесс мог продолжить работу с места остановки, в случае перезапуска, а не начинал перегрузку PostgesSQL с начала.

**Основные требования  к проекту**:

- Скрипт должен восстановливать подключения к базам данных при потере соединения. Повторять запросы с постепенныи повышением времени между ними. Реализовано в виде параметрического декоратора.

- Скрипт должен сохранять состояния в yaml-файле. При перезапуске процесс продолжит работу с места остановки. В случае обновления или добавления новых записей будут обработаны и перенесены в индекс Elasticsearch только новые записи

- Скрипт должен загружать настройки для логгирования, создания индекса Elasticsearch и подключения к базам данных из отдельного yaml-файла

- Скрипт должен запускаться в контейнере. Запуск осуществляется в четырех докер-контейнерах: ElasticSearch, PostgresSQL, ETL-процесс и Kibana(для удобства проверки, что данные загружены в ES корректно) с помощью docker-compose.

- Применить в проекте аннотацию типов, логирование, дата-классы для представления записей базы данных и пакет pydantic для валидации настроек.

### Стек технологий
- python 3.9
- PostgreSQL 13
- elasticsearch 7.15.2
- docker

### Запуск приложения
Для запуска приложения:

1. склонируйте репозиторий
```bash
git clone 'путь до репозитория'
```
2. создайтеи и запустите виртуальное окружение
```bash
python -m venv venv
source venv/bin/activate
```
3. установите внешние зависимости из requirements.txt
```bash
pip install -r requirements.txt
```
4. запустите docker-compose
```bash
docker compose up
```

Докер соберет необходимые образы и запустит контейнеры.
### Структура репозитория
**корневая директория**:

- **.env** - файл с необходимыми для запуска проекта переменными окружения
- **Dockerfile** - инструкции для сборки docker-образа ETL-процесса
- **docker-compose.yaml** - конфигурация контейнеров docker
- **requirements.txt** - список внешних зависимостей проекта

*Хотя не рекомендуется сохранять в репозитории чувствительные данные (пароли, логины и прочее), но для удобства запуска контейнеров и подключения к базам данных все необходимые данные указаны файлах .env и postgres_to_es/config.py.*

**директория src/db:**

- **001_init_user_db.sh** - bash-скрипт, запустится при первом запуске контейнера PostgreSQL
- **movies_db_schema.ddl** - структура базы данных PostgreSQL
- **movies_db_content.dump** - исходные данные для заполнения базы данных PostgreSQL

*Файлы из src/db будут скопированы в контейнер PostgreSQL и при первом запуске контейнера запустится скрипт 001_init_user_db.sh. В результате будет создан новый пользователь и база данных в соответствии с переменными окружения указанными в файле .env. В базе данных будут созданы схема, таблицы, индексы указанные в файле movies_db_schema.ddl и база будет заполнена данными из movies_db_content.dump.*

**директория postgres_to_es:**

- **backoff.py** - функция-параметрический декоратор для восстановления подключения к базам данных
- **config.py** - pydantic модели для валидации параметров настройки из файла config.yaml
- **config.yaml** - файл с настройками ETL-процесса, подключений к базам данных, логгирования
- **dataclass.py** - датаклассы для представления записей в PostgreSQL
- **index_config.json** - схема индекса в Elasticsearch
- **main.py** - ETL-процесс
- **sql.py** - SQL-запросы для извлечения данных из PostgreSQL
- **state.py** - для работы с сохранением состояния